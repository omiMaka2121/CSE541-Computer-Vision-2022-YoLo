{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom os import listdir\nfrom os.path import join, isfile, isdir\nfrom glob import glob\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import backend as K\n\nfrom PIL import Image\nsns.set()\nfrom tqdm import tqdm\n%matplotlib inline\n\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-13T06:46:03.306700Z","iopub.execute_input":"2023-04-13T06:46:03.307457Z","iopub.status.idle":"2023-04-13T06:46:03.317510Z","shell.execute_reply.started":"2023-04-13T06:46:03.307420Z","shell.execute_reply":"2023-04-13T06:46:03.316256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys, os, time, imageio \nimport numpy as np, pandas as pd  \n\nimport matplotlib.pyplot as plt \nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nfrom PIL import Image \n\nimport torch \nimport torchvision.utils as vutils \nimport torchvision.transforms as transforms \n\nfrom keras import models, layers, optimizers \nfrom keras.models import Sequential \n#from keras.preprocessing.image import array_to_img, img_to_array, load_img \n\nfrom tensorflow.keras.utils import array_to_img,img_to_array, load_img \n\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:08.417282Z","iopub.execute_input":"2023-04-13T06:46:08.418056Z","iopub.status.idle":"2023-04-13T06:46:08.425038Z","shell.execute_reply.started":"2023-04-13T06:46:08.418017Z","shell.execute_reply":"2023-04-13T06:46:08.423855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df = pd.read_csv(\"../input/nih-chest-xray-dataset/test.csv\")\n#test_df.head()\nall_xray_df = pd.read_csv(\"../input/chestxray8-dataframe/train_df.csv\")\nall_xray_df.drop(['No Finding'], axis = 1, inplace = True)\nall_xray_df.head()\n\ndata_dir1 = '../input/data/'\ndata_dir2 = '../input/chestxray8-dataframe/'\ntrain_df = pd.read_csv(data_dir1 + 'Data_Entry_2017.csv')\nimage_label_map = pd.read_csv(data_dir2 + 'train_df.csv')\nbad_labels = pd.read_csv(data_dir2 + 'cxr14_bad_labels.csv')\n\n# Listing all the .png filepaths\nimage_paths = glob(data_dir1+'images_*/images/*.png')\nprint(f'Total image files found : {len(image_paths)}')\nprint(f'Total number of image labels: {image_label_map.shape[0]}')\nprint(f'Unique patients: {len(train_df[\"Patient ID\"].unique())}')\n\nimage_label_map.drop(['No Finding'], axis = 1, inplace = True)\nlabels = image_label_map.columns[2:-1]\nlabels\nimage_label_map.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:09.563820Z","iopub.execute_input":"2023-04-13T06:46:09.564198Z","iopub.status.idle":"2023-04-13T06:46:10.657761Z","shell.execute_reply.started":"2023-04-13T06:46:09.564165Z","shell.execute_reply":"2023-04-13T06:46:10.656617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Cardiomegaly', \n          'Emphysema', \n          'Effusion', \n          'Hernia', \n          'Infiltration', \n          'Mass', \n          'Nodule', \n          'Atelectasis',\n          'Pneumothorax',\n          'Pleural_Thickening', \n          'Pneumonia', \n          'Fibrosis', \n          'Edema', \n          'Consolidation']","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:10.659775Z","iopub.execute_input":"2023-04-13T06:46:10.660628Z","iopub.status.idle":"2023-04-13T06:46:10.666863Z","shell.execute_reply.started":"2023-04-13T06:46:10.660589Z","shell.execute_reply":"2023-04-13T06:46:10.665702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.rename(columns={\"Image Index\": \"Index\"}, inplace = True)\nimage_label_map.rename(columns={\"Image Index\": \"Index\"}, inplace = True)\ntrain_df = train_df[~train_df.Index.isin(bad_labels.Index)]\ntrain_df.shape\n\nIndex =[]\nfor path in image_paths:\n    Index.append(path.split('/')[5])\nindex_path_map = pd.DataFrame({'Index':Index, 'FilePath': image_paths})\nindex_path_map.head()\n\n# Merge the absolute path of the images to the main dataframe\npd.merge(train_df, index_path_map, on='Index', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:10.668626Z","iopub.execute_input":"2023-04-13T06:46:10.669075Z","iopub.status.idle":"2023-04-13T06:46:10.865515Z","shell.execute_reply.started":"2023-04-13T06:46:10.669040Z","shell.execute_reply":"2023-04-13T06:46:10.864407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_df = pd.merge(train_df, index_path_map, on='Index', how='left')\nmerge_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:10.936324Z","iopub.execute_input":"2023-04-13T06:46:10.936990Z","iopub.status.idle":"2023-04-13T06:46:11.048196Z","shell.execute_reply.started":"2023-04-13T06:46:10.936944Z","shell.execute_reply":"2023-04-13T06:46:11.046930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.2 Preparing Images**\n1. Normalize the mean and standard deviation of the data\n2. Shuffle the input after each epoch.\n3. Set the image size to be 320px by 320px","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE=[256, 256]\nEPOCHS = 20\n# BATCH_SIZE = 8 * strategy.num_replicas_in_sync\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:50:04.562528Z","iopub.execute_input":"2023-04-13T09:50:04.562925Z","iopub.status.idle":"2023-04-13T09:50:04.569273Z","shell.execute_reply.started":"2023-04-13T09:50:04.562874Z","shell.execute_reply":"2023-04-13T09:50:04.568168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_generator(df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    \n    print(\"getting testing generators...\")\n    \n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True)\n    \n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return test_generator\n\ntrain_generator = get_generator(df = image_label_map,\n                                      image_dir = None, \n                                      x_col = 'FilePath',\n                                      y_cols = labels, \n                                      batch_size=BATCH_SIZE,\n                                      target_w = IMAGE_SIZE[0], \n                                      target_h = IMAGE_SIZE[1] \n                                      )","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:51:14.520702Z","iopub.execute_input":"2023-04-13T09:51:14.521138Z","iopub.status.idle":"2023-04-13T09:56:15.999387Z","shell.execute_reply.started":"2023-04-13T09:51:14.521102Z","shell.execute_reply":"2023-04-13T09:56:15.998311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Solving Class Imbalance for two classes:**","metadata":{}},{"cell_type":"code","source":"def class_maker(name):\n    save_list = merge_df[merge_df['Finding Labels'].str.contains(name)][\"FilePath\"].tolist()\n    return save_list","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:11.081851Z","iopub.execute_input":"2023-04-13T06:46:11.082805Z","iopub.status.idle":"2023-04-13T06:46:11.088653Z","shell.execute_reply.started":"2023-04-13T06:46:11.082744Z","shell.execute_reply":"2023-04-13T06:46:11.087395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Emphysema = class_maker(\"Emphysema\")\nEffusion = class_maker(\"Effusion\")\nHernia = class_maker(\"Hernia\")\nInfiltration = class_maker(\"Infiltration\")\nMass = class_maker(\"Mass\")\nNodule = class_maker(\"Nodule\")\nAtelectasis = class_maker(\"Atelectasis\")\nPneumothorax = class_maker(\"Pneumothorax\")\nPleural_Thickening = class_maker(\"Pleural_Thickening\")\nPneumonia = class_maker(\"Pneumonia\")\nFibrosis = class_maker(\"Fibrosis\")\nEdema = class_maker(\"Edema\")\nConsolidation = class_maker(\"Consolidation\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:11.977140Z","iopub.execute_input":"2023-04-13T06:46:11.978331Z","iopub.status.idle":"2023-04-13T06:46:12.549022Z","shell.execute_reply.started":"2023-04-13T06:46:11.978283Z","shell.execute_reply":"2023-04-13T06:46:12.547953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the file paths\nimport shutil\nimport os\n\nos.mkdir('/kaggle/working/Pneumonia')\ndestination_folder = '/kaggle/working/Pneumonia'\nfor i in Pneumonia:\n    shutil.copy(i,'/kaggle/working/Pneumonia/'+str(i.split('/')[5]))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:12.551211Z","iopub.execute_input":"2023-04-13T06:46:12.551700Z","iopub.status.idle":"2023-04-13T06:46:12.579554Z","shell.execute_reply.started":"2023-04-13T06:46:12.551662Z","shell.execute_reply":"2023-04-13T06:46:12.578049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _time(start, end): \n    # if in seconds \n    if (end-start)<60: \n        wall_time = f'{round((end-start),2)}sec'\n    # if in minute(s)  \n    elif (end-start)>=3600: \n        wall_time = f'{int((end-start)/3600)}h {int(((end-start)%3600)/60)}min {round((end-start)%60,2)}sec'\n    # if in houre(s)  \n    else: \n        wall_time = f'{int((end-start)/60)}min {round((end-start)%60,2)}sec'\n    return wall_time","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:13.146269Z","iopub.execute_input":"2023-04-13T06:46:13.147490Z","iopub.status.idle":"2023-04-13T06:46:13.154073Z","shell.execute_reply.started":"2023-04-13T06:46:13.147431Z","shell.execute_reply":"2023-04-13T06:46:13.152947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(data_path, dim=(128, 128), rand_shuffle=True): \n    start = time.time() \n    imgs_data = []         \n    sample_size = len(data_path)\n    for idx, im_path in enumerate(data_path): \n        if idx%(sample_size//10)==0:\n            print('Processing index {:05d} of {:05d} ==> {:03d}%'\\\n                  .format(idx, sample_size, round(100*idx/sample_size))) \n        img = img_to_array(load_img(im_path, target_size = dim)) \n        imgs_data.append(img) \n        \n    # to float \n    imgs_data = np.array(imgs_data).astype('float32') \n    # scale to [0,1] (note the . after 255 - float)\n    imgs_data = imgs_data/255. #for formalizing to [-1,1] ==> (imgs_data - 127.5)/127.5 \n    \n    # shuffle the data \n    if rand_shuffle: \n        idx = np.arange(imgs_data.shape[0])\n        np.random.shuffle(idx) \n        imgs_data = imgs_data[idx,:,:,:] \n    \n    print(f\"Hey! the calculations are done in {_time(start, time.time())}\")\n    return imgs_data","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:16.240124Z","iopub.execute_input":"2023-04-13T06:46:16.240518Z","iopub.status.idle":"2023-04-13T06:46:16.249415Z","shell.execute_reply.started":"2023-04-13T06:46:16.240484Z","shell.execute_reply":"2023-04-13T06:46:16.248295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Starting for PNEUMONIA X-Ray images ...')\n\n# Root directory for dataset\nXRay_pneumonial = glob(\"/kaggle/working/Pneumonia/*.png\")\nX_pneumonial = get_data(XRay_pneumonial)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:16.840288Z","iopub.execute_input":"2023-04-13T06:46:16.840656Z","iopub.status.idle":"2023-04-13T06:46:42.352050Z","shell.execute_reply.started":"2023-04-13T06:46:16.840623Z","shell.execute_reply":"2023-04-13T06:46:42.350791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_grid(data_images, nrows=4, ncols=5, plot_grid=True):\n    # save the started time \n    start = time.time() \n    # Number of GPUs available. Use 0 for CPU mode. \n    ngpu = 1 \n    # Decide which device we want to run on \n    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n    # Rearange the shaphe of the data \n    data_transp = [np.transpose(data_images[i,:,:]) for i in range(data_images[:nrows*ncols].shape[0])]\n    # From to torch type for the grid \n    data_transp = torch.Tensor(data_transp)\n    print(f'The shape is reordered from {data_images.shape[1:]} to {data_transp.shape[1:]} in {_time(start, time.time())}')\n    \n    # Make the grid \n    grid_images = np.transpose(\n        vutils.make_grid(\n            data_transp.to(device)[:nrows*ncols], \n            nrow=nrows,\n            padding=2,\n            normalize=True,\n            scale_each=True,\n            pad_value=1,\n        ).cpu(), axes=(2,1,0))\n        \n    # Show the output grid \n    if plot_grid:\n        plt.figure(figsize=(12,12)) \n        plt.axis(\"off\") \n        plt.title(f'Grid of {nrows*ncols} real images', fontsize=27)\n        plt.imshow(grid_images)\n        \n    return grid_images\n\ngrid_X_pneumonial = define_grid(X_pneumonial, plot_grid=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:42.354398Z","iopub.execute_input":"2023-04-13T06:46:42.355600Z","iopub.status.idle":"2023-04-13T06:46:42.457669Z","shell.execute_reply.started":"2023-04-13T06:46:42.355557Z","shell.execute_reply":"2023-04-13T06:46:42.456557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2)= plt.subplots(nrows=1, ncols=2, figsize=(19, 8))\n\nax1.imshow(grid_X_pneumonial); ax1.axis('off')\nax1.set_title(label = 'Grid of X-Ray NORMAL images', fontsize = 27)\n\nax2.imshow(grid_X_pneumonial); ax2.axis('off')\nax2.set_title(label = 'Grid of X-Ray PNEUMONIA images', fontsize = 27)\n\nplt.tight_layout(pad=1.08, h_pad=None, w_pad=None, rect=[0, 0.03, 1, 0.95])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:42.459335Z","iopub.execute_input":"2023-04-13T06:46:42.459736Z","iopub.status.idle":"2023-04-13T06:46:43.456191Z","shell.execute_reply.started":"2023-04-13T06:46:42.459697Z","shell.execute_reply":"2023-04-13T06:46:43.455289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images to use (will be changed)\n#n_images = 12_000 \n\n# Number of training epochs\nn_epoch = 200 \n\n# Batch size during training \nbatch_size = 128 \n\n# Size of z latent vector (i.e. size of generator input) \nlatent_dim = 100 \n\n# Spatial size of training images. All images will be resized to this size \ncols, rows = 128, 128 \n\n# Number of channels in the training images. For RGB color images this is 3\nchannels = 3 \ndim = cols, rows # height, width \nin_shape = (cols, rows, channels) # height, width, color \n\n# Learning rate for optimizers\nlr = 0.0002\n\n# Beta1 hyperparam for Adam optimizers\nbeta1 = 0.5\n\n# Number of GPUs available. Use 0 for CPU mode.\nngpu = 1 \n\n# plot ncols images in row and nrows images in colomn\nnrows, ncols = 3, 4","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:43.458443Z","iopub.execute_input":"2023-04-13T06:46:43.459416Z","iopub.status.idle":"2023-04-13T06:46:43.467589Z","shell.execute_reply.started":"2023-04-13T06:46:43.459376Z","shell.execute_reply":"2023-04-13T06:46:43.466544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_discriminator(in_shape=(128,128,3)): \n    \n    model = models.Sequential() \n    # normal \n    model.add(layers.Conv2D(128, (5,5), padding='same', input_shape=in_shape)) \n    model.add(layers.LeakyReLU(alpha=0.2)) \n    # downsample to 64x64 \n    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same')) \n    model.add(layers.LeakyReLU(alpha=0.2)) \n    # downsample to 32x32 \n    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same')) \n    model.add(layers.LeakyReLU(alpha=0.2)) \n    # downsample to 16x16 \n    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same')) \n    model.add(layers.LeakyReLU(alpha=0.2)) \n    # downsample to 8x8 \n    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same')) \n    model.add(layers.LeakyReLU(alpha=0.2)) \n    # classifier \n    model.add(layers.Flatten()) \n    model.add(layers.Dropout(0.4)) \n    model.add(layers.Dense(1, activation='sigmoid')) \n    # compile model \n    opt = optimizers.Adam(lr=0.0002, beta_1=0.5) \n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:43.469488Z","iopub.execute_input":"2023-04-13T06:46:43.469845Z","iopub.status.idle":"2023-04-13T06:46:43.486622Z","shell.execute_reply.started":"2023-04-13T06:46:43.469811Z","shell.execute_reply":"2023-04-13T06:46:43.485503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_generator(latent_dim):\n    \n    model = models.Sequential()\n    # foundation for 8x8 feature maps\n    n_nodes = 128*8*8\n    model.add(layers.Dense(n_nodes, input_dim=latent_dim))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Reshape((8, 8, 128)))\n    # upsample to 16x16\n    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    # upsample to 32x32\n    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    # upsample to 64x64\n    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    # upsample to 128x128\n    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    # output layer 128x128x3\n    model.add(layers.Conv2D(3, (5,5), activation='tanh', padding='same'))\n    return model \n\n#input of G\ndef generate_latent_points(latent_dim, n_samples):\n    # generate points in the latent space\n    x_input = np.random.randn(latent_dim*n_samples)\n    # reshape into a batch of inputs for the network\n    x_input = x_input.reshape(n_samples, latent_dim)\n    return x_input \n\n# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(g_model, latent_dim, n_samples):\n    # generate points in latent space\n    x_input = generate_latent_points(latent_dim, n_samples)\n    # predict outputs\n    X = g_model.predict(x_input)\n    # create 'fake' class labels (0)\n    y = np.zeros((n_samples, 1))\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:43.488149Z","iopub.execute_input":"2023-04-13T06:46:43.489216Z","iopub.status.idle":"2023-04-13T06:46:43.502530Z","shell.execute_reply.started":"2023-04-13T06:46:43.489177Z","shell.execute_reply":"2023-04-13T06:46:43.501444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_gan(g_model, d_model): \n    # make weights in the discriminator not trainable\n    d_model.trainable = False \n    # connect them\n    model = models.Sequential()\n    # add generator\n    model.add(g_model)\n    # add the discriminator\n    model.add(d_model)\n    # compile model\n    opt = optimizers.Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model\n\n# retrive real samples\ndef get_real_samples(dataset, n_samples):\n    # choose random instances\n    ix = np.random.randint(0, dataset.shape[0], n_samples)\n    # retrieve selected images\n    X = dataset[ix]\n    # set 'real' class labels (1)\n    y = np.ones((n_samples, 1))\n    return X, y\n\n# create and save a plot of generated images \ndef show_generated(generated, epoch, nrows=4, ncols=5):\n    #[-1,1] -> [0,1] \n    #generated = (generated+1)/2 \n    #generated = (generated[:ncols*nrows]*127.5)+127.5 \n    #generated = generated*255 \n    plt.figure(figsize=(10,10)) \n    for idx in range(nrows*ncols): \n        plt.subplot(nrows, ncols, idx+1) \n        plt.imshow(generated[idx]) \n        plt.axis('off') \n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch+1)) \n    plt.show() \n\n# evaluate the discriminator and plot generated images \ndef summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n    # prepare real samples\n    X_real, y_real = get_real_samples(dataset, n_samples)\n    # evaluate discriminator on real examples \n    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n    # prepare fake examples \n    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n    # evaluate discriminator on fake examples \n    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n    # summarize discriminator performance \n    print('> Accuracy at epoch %d [real: %.0f%%, fake: %.0f%%]'%(epoch+1, acc_real*100, acc_fake*100))\n    # show plot \n    show_generated(x_fake, epoch)  \n    \ndef plot_loss(loss):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Generator and Discriminator Loss During Training\", fontsize=20) \n    plt.plot(loss[0], label=\"D_real\") \n    plt.plot(loss[1], label=\"D_fake\") \n    plt.plot(loss[2], label=\"G\") \n    plt.xlabel(\"Iteration\", fontsize=20); plt.ylabel(\"Loss\", fontsize=20) \n    plt.legend(); plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:43.504010Z","iopub.execute_input":"2023-04-13T06:46:43.505242Z","iopub.status.idle":"2023-04-13T06:46:43.521274Z","shell.execute_reply.started":"2023-04-13T06:46:43.505191Z","shell.execute_reply":"2023-04-13T06:46:43.520127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(g_model, d_model, gan_model, dataset, latent_dim=100, n_epochs=100, n_batch=128):\n    \n    start = time.time() \n    bat_per_epo = int(dataset.shape[0]/n_batch) \n    half_batch = int(n_batch/2) \n    loss1, loss2, loss3 = [], [], [] \n    fake_liste = [] \n    \n    # manually enumerate epochs\n    print('Training Start...')\n    for i in range(n_epochs):\n        start1 = time.time()\n        # enumerate batches over the training set\n        for j in range(bat_per_epo):\n            # get randomly selected 'real' samples\n            X_real, y_real = get_real_samples(dataset, half_batch)\n            # update discriminator model weights\n            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n            # generate 'fake' examples\n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n            # update discriminator model weights\n            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n            # create inverted labels for the fake samples\n            y_gan = np.ones((n_batch, 1))\n            # update the generator via the discriminator's error\n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            # summarize loss on this batch\n            loss1.append(d_loss1); loss2.append(d_loss2); loss3.append(g_loss) \n        \n        print('Epoch: {:03d}/{:03d}, Loss: [D_real = {:2.3f}, D_fake = {:2.3f}, G = {:2.3f}], time: {:s}'\\\n              .format(i+1,n_epochs,d_loss1,d_loss2,g_loss, _time(start1,time.time())))\n        # evaluate the model performance \n        if (i+1)%(n_epochs//10) == 0: \n            # Save and show generated images \n            summarize_performance(i, g_model, d_model, dataset, latent_dim) \n        \n    print('Total time for training {} epochs is {} sec'.format(n_epochs, _time(start, time.time())))\n    \n    # Show loss curves \n    loss = (loss1, loss2, loss3) \n    plot_loss(loss)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:43.524927Z","iopub.execute_input":"2023-04-13T06:46:43.525442Z","iopub.status.idle":"2023-04-13T06:46:43.538308Z","shell.execute_reply.started":"2023-04-13T06:46:43.525415Z","shell.execute_reply":"2023-04-13T06:46:43.537367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = define_discriminator() \ngenerator = define_generator(latent_dim) \n\n# create the gan \ngan = define_gan(generator, discriminator)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T06:46:43.540049Z","iopub.execute_input":"2023-04-13T06:46:43.540428Z","iopub.status.idle":"2023-04-13T06:46:43.837350Z","shell.execute_reply.started":"2023-04-13T06:46:43.540393Z","shell.execute_reply":"2023-04-13T06:46:43.835023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model \ntrain(generator, discriminator, gan, X_pneumonial, latent_dim, n_epochs=n_epoch, n_batch=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T08:38:08.081822Z","iopub.execute_input":"2023-04-11T08:38:08.082188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Code for Hernia**","metadata":{}},{"cell_type":"code","source":"# Set the file paths\nimport shutil\nimport os\n\nos.mkdir('/kaggle/working/Hernia')\ndestination_folder = '/kaggle/working/Hernia'\nfor i in Pneumonia:\n    shutil.copy(i,'/kaggle/working/Hernia/'+str(i.split('/')[5]))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:48:18.714989Z","iopub.execute_input":"2023-04-13T07:48:18.715968Z","iopub.status.idle":"2023-04-13T07:48:39.433667Z","shell.execute_reply.started":"2023-04-13T07:48:18.715917Z","shell.execute_reply":"2023-04-13T07:48:39.432580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Starting for Hernia X-Ray images ...')\n\n# Root directory for dataset\nXRay_hernia = glob(\"/kaggle/working/Hernia/*.png\")\nX_hernia = get_data(XRay_hernia)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:48:54.966945Z","iopub.execute_input":"2023-04-13T07:48:54.967684Z","iopub.status.idle":"2023-04-13T07:49:15.178236Z","shell.execute_reply.started":"2023-04-13T07:48:54.967648Z","shell.execute_reply":"2023-04-13T07:49:15.176930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_grid(data_images, nrows=4, ncols=5, plot_grid=True):\n    # save the started time \n    start = time.time() \n    # Number of GPUs available. Use 0 for CPU mode. \n    ngpu = 1 \n    # Decide which device we want to run on \n    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n    # Rearange the shaphe of the data \n    data_transp = [np.transpose(data_images[i,:,:]) for i in range(data_images[:nrows*ncols].shape[0])]\n    # From to torch type for the grid \n    data_transp = torch.Tensor(data_transp)\n    print(f'The shape is reordered from {data_images.shape[1:]} to {data_transp.shape[1:]} in {_time(start, time.time())}')\n    \n    # Make the grid \n    grid_images = np.transpose(\n        vutils.make_grid(\n            data_transp.to(device)[:nrows*ncols], \n            nrow=nrows,\n            padding=2,\n            normalize=True,\n            scale_each=True,\n            pad_value=1,\n        ).cpu(), axes=(2,1,0))\n        \n    # Show the output grid \n    if plot_grid:\n        plt.figure(figsize=(12,12)) \n        plt.axis(\"off\") \n        plt.title(f'Grid of {nrows*ncols} real images', fontsize=27)\n        plt.imshow(grid_images)\n        \n    return grid_images\n\ngrid_X_hernia = define_grid(X_hernia, plot_grid=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:49:15.181346Z","iopub.execute_input":"2023-04-13T07:49:15.181998Z","iopub.status.idle":"2023-04-13T07:49:15.287046Z","shell.execute_reply.started":"2023-04-13T07:49:15.181954Z","shell.execute_reply":"2023-04-13T07:49:15.285937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2)= plt.subplots(nrows=1, ncols=2, figsize=(19, 8))\n\nax1.imshow(grid_X_hernia); ax1.axis('off')\nax1.set_title(label = 'Grid of X-Ray Hernia images', fontsize = 27)\n\nax2.imshow(grid_X_hernia); ax2.axis('off')\nax2.set_title(label = 'Grid of X-Ray Hernia images', fontsize = 27)\n\nplt.tight_layout(pad=1.08, h_pad=None, w_pad=None, rect=[0, 0.03, 1, 0.95])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:49:15.288783Z","iopub.execute_input":"2023-04-13T07:49:15.289430Z","iopub.status.idle":"2023-04-13T07:49:16.535461Z","shell.execute_reply.started":"2023-04-13T07:49:15.289391Z","shell.execute_reply":"2023-04-13T07:49:16.534447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images to use (will be changed)\n#n_images = 12_000 \n\n# Number of training epochs\nn_epoch = 500 \n\n# Batch size during training \nbatch_size = 64 \n\n# Size of z latent vector (i.e. size of generator input) \nlatent_dim = 100 \n\n# Spatial size of training images. All images will be resized to this size \ncols, rows = 128, 128 \n\n# Number of channels in the training images. For RGB color images this is 3\nchannels = 3 \ndim = cols, rows # height, width \nin_shape = (cols, rows, channels) # height, width, color \n\n# Learning rate for optimizers\nlr = 0.0002\n\n# Beta1 hyperparam for Adam optimizers\nbeta1 = 0.5\n\n# Number of GPUs available. Use 0 for CPU mode.\nngpu = 1 \n\n# plot ncols images in row and nrows images in colomn\nnrows, ncols = 3, 4","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:49:16.538485Z","iopub.execute_input":"2023-04-13T07:49:16.541149Z","iopub.status.idle":"2023-04-13T07:49:16.553878Z","shell.execute_reply.started":"2023-04-13T07:49:16.541110Z","shell.execute_reply":"2023-04-13T07:49:16.552967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator_hernia = define_discriminator() \ngenerator_hernia = define_generator(latent_dim) \n\n# create the gan \ngan_hernia = define_gan(generator_hernia, discriminator_hernia)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:49:16.555458Z","iopub.execute_input":"2023-04-13T07:49:16.556255Z","iopub.status.idle":"2023-04-13T07:49:16.958546Z","shell.execute_reply.started":"2023-04-13T07:49:16.556209Z","shell.execute_reply":"2023-04-13T07:49:16.957386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model \ntrain(generator_hernia, discriminator_hernia, gan_hernia, X_hernia, latent_dim, n_epochs=n_epoch, n_batch=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T07:49:16.963517Z","iopub.execute_input":"2023-04-13T07:49:16.965830Z","iopub.status.idle":"2023-04-13T09:26:31.062019Z","shell.execute_reply.started":"2023-04-13T07:49:16.965793Z","shell.execute_reply":"2023-04-13T09:26:31.060856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_hernia.save_weights(\"generator_hernia.h5\")\ndiscriminator_hernia.save_weights(\"discriminator_hernia.h5\")\ngan_hernia.save_weights(\"gan_hernia.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:26:31.064743Z","iopub.execute_input":"2023-04-13T09:26:31.065953Z","iopub.status.idle":"2023-04-13T09:26:31.150227Z","shell.execute_reply.started":"2023-04-13T09:26:31.065892Z","shell.execute_reply":"2023-04-13T09:26:31.149231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"/kaggle/working/GAN_hernia\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:26:31.151808Z","iopub.execute_input":"2023-04-13T09:26:31.152210Z","iopub.status.idle":"2023-04-13T09:26:31.159348Z","shell.execute_reply.started":"2023-04-13T09:26:31.152170Z","shell.execute_reply":"2023-04-13T09:26:31.157181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\n\n# Generate 10 images using the GAN\nfor i in range(4000):\n    noise = np.random.normal(0, 1, (1, 100))\n    generated_image = generator_hernia.predict(noise)[0]\n    generated_image = (generated_image * 127.5) + 127.5\n    generated_image = generated_image.astype(np.uint8)\n    \n    # Save the generated image to disk\n    img = Image.fromarray(generated_image)\n    img.save(os.path.join('/kaggle/working/GAN_hernia', f'generated_image_hernia{i}.png'))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:26:31.162407Z","iopub.execute_input":"2023-04-13T09:26:31.163165Z","iopub.status.idle":"2023-04-13T09:30:52.702571Z","shell.execute_reply.started":"2023-04-13T09:26:31.163133Z","shell.execute_reply":"2023-04-13T09:30:52.701190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"Data\", 'zip', '/kaggle/input/data')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T10:40:21.371502Z","iopub.execute_input":"2023-04-13T10:40:21.371887Z"},"trusted":true},"execution_count":null,"outputs":[]}]}